import json
from typing import List, Tuple
from langchain_core.documents import Document
from langchain_upstage import ChatUpstage
from langchain.prompts import PromptTemplate
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re

# ğŸ’¡ LLM ê¸°ë°˜ ì ìˆ˜ í‰ê°€ í•¨ìˆ˜ (MMRì— ì‚¬ìš©í•  ì ìˆ˜ ìƒì„±)
def _get_llm_relevance_scores(api_key: str, base_url: str, chat_model: str, query: str, documents: List[Document]) -> List[float]:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ê° ë¬¸ì„œì˜ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ 0~100 ì‚¬ì´ë¡œ í‰ê°€í•©ë‹ˆë‹¤."""
    llm = ChatUpstage(
        api_key=api_key,
        base_url=base_url,
        model=chat_model,
        temperature=0.0, # ì¼ê´€ì„±ì„ ìœ„í•´ 0.0 ì„¤ì •
    )
    
    # JSON ì¶œë ¥ì„ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸
    template = """
    ë„ˆëŠ” ë¬¸ì„œ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì•¼. ì•„ë˜ì˜ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë¬¸ì„œ ë‚´ìš©ì„ ë³´ê³ , 
    ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë° ì´ ë¬¸ì„œê°€ ì–¼ë§ˆë‚˜ ìœ ìš©í•œì§€ 0ì ë¶€í„° 100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¡œ í‰ê°€í•´.

    ---
    ì‚¬ìš©ì ì§ˆë¬¸: {query}

    ---
    ë¬¸ì„œ ë‚´ìš©:
    {document_content}

    ---
    ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•´. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” ì¼ì ˆ ì¶”ê°€í•˜ì§€ ë§ˆ.
    {{"relevance_score": ì ìˆ˜}}
    """
    
    prompt = PromptTemplate.from_template(template)
    scores = []
    
    #ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ LLM í‰ê°€ ì‹¤í–‰
    for doc in documents:
        try:
            # LLM Chain ì‹¤í–‰
            response = llm.invoke(
                prompt.format(
                    query=query, 
                    document_content=doc.page_content
                )
            ).content
            
            # ğŸŸ¢ JSON ì¶”ì¶œ ê°•í™”: ì‘ë‹µì—ì„œ ì²« ë²ˆì§¸ JSON ê°ì²´ë¥¼ ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ
            match = re.search(r'\{.*\}', response.strip(), re.DOTALL)
            
            if match:
                score_json_str = match.group(0)
                score_json = json.loads(score_json_str)
                score = float(score_json.get("relevance_score", 0)) / 100.0  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
                scores.append(score)
                doc.metadata['llm_relevance_score'] = score * 100.0 # ë©”íƒ€ë°ì´í„°ì—ëŠ” 0~100 ì €ì¥
            else:
                raise ValueError("LLM ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            # íŒŒì‹± ì˜¤ë¥˜ ë˜ëŠ” ê¸°íƒ€ ì˜¤ë¥˜ ë°œìƒ ì‹œ 0ì ìœ¼ë¡œ ì²˜ë¦¬
            print(f"âš ï¸ LLM ì ìˆ˜ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            scores.append(0.0)
            doc.metadata['llm_relevance_score'] = 0.0
            
    return scores

# MMR ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë¬¸ì„œ ìˆœìœ„ ê²°ì •
def rerank_documents_mmr(api_key: str, base_url: str, chat_model: str, embeddings: object, query: str, documents: List[Document], top_k: int = 5, lambda_mult: float = 0.5) -> List[Document]:
    """
    LLM ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ MMR(Maximal Marginal Relevance)ì„ ì ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ì¬ìˆœìœ„í™”í•©ë‹ˆë‹¤.

    Args:
        api_key, base_url, chat_model: LLM ì ìˆ˜ í‰ê°€ìš© ì¸ì.
        embeddings (object): ì„ë² ë”© ëª¨ë¸ ê°ì²´ (src/embedding.pyì—ì„œ ê°€ì ¸ì˜¨ ê²ƒ).
        query (str): ì‚¬ìš©ì ì§ˆë¬¸.
        documents (List[Document]): Retrieverë¡œë¶€í„° ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸.
        top_k (int): ìµœì¢…ì ìœ¼ë¡œ ì„ íƒí•  ë¬¸ì„œì˜ ê°œìˆ˜.
        lambda_mult (float): MMR ëŒë‹¤ ê°’ (0: ë‹¤ì–‘ì„± ìš°ì„ , 1: ê´€ë ¨ì„± ìš°ì„ ).

    Returns:
        List[Document]: MMRì„ í†µí•´ ì¬ìˆœìœ„í™”ëœ ìƒìœ„ Kê°œ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸.
    """
    if not documents or top_k == 0:
        return []

    # 1. LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê´€ë ¨ì„± ì ìˆ˜ íšë“ (Relevance Score)
    llm_scores = _get_llm_relevance_scores(api_key, base_url, chat_model, query, documents)
    
    # 2. ë¬¸ì„œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (Diversity Score ê³„ì‚°ìš©)
    document_texts = [doc.page_content for doc in documents]
    
    # ì£¼ì˜: embeddings ê°ì²´ëŠ” langchainì˜ UpstageEmbeddings ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
    try:
        doc_embeddings = np.array(embeddings.embed_documents(document_texts))
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}. 'embeddings' ê°ì²´ê°€ ì˜¬ë°”ë¥¸ LangChain Embeddings ê°ì²´ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return []

    # 3. ë¬¸ì„œ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° (Diversity Term)
    # ë¬¸ì„œê°€ 1ê°œì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ np.eye(N)ìœ¼ë¡œ ì´ˆê¸°í™”
    if len(doc_embeddings) == 1:
        similarity_matrix = np.array([[1.0]])
    else:
        similarity_matrix = cosine_similarity(doc_embeddings)

    # 4. MMR ì•Œê³ ë¦¬ì¦˜ ì ìš©
    
    # ì´ˆê¸°í™”
    N = len(documents)
    selected_indices = []
    unselected_indices = list(range(N))
    
    for _ in range(min(top_k, N)):
        if not unselected_indices:
            break

        mmr_scores = []
        
        # ì„ íƒë˜ì§€ ì•Šì€ ê° ë¬¸ì„œì— ëŒ€í•´ MMR ì ìˆ˜ ê³„ì‚°
        for i in unselected_indices:
            # ê´€ë ¨ì„± í•­ (Relevance Term): LLM ì ìˆ˜ (0~1)
            relevance_term = llm_scores[i]
            
            # ë‹¤ì–‘ì„± í•­ (Diversity Term): ì„ íƒëœ ë¬¸ì„œë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if not selected_indices:
                diversity_term = 0.0
            else:
                max_similarity = np.max(similarity_matrix[i, selected_indices])
                diversity_term = max_similarity
            
            # MMR = lambda * Relevance - (1 - lambda) * Diversity
            mmr_score = (lambda_mult * relevance_term) - ((1 - lambda_mult) * diversity_term)
            mmr_scores.append((mmr_score, i))
        
        # MMR ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ë¬¸ì„œ ì„ íƒ
        best_score, best_index = max(mmr_scores)
        
        # ì„ íƒëœ ì¸ë±ìŠ¤ ì¶”ê°€ ë° ë¯¸ì„ íƒ ì¸ë±ìŠ¤ì—ì„œ ì œê±°
        selected_indices.append(best_index)
        unselected_indices.remove(best_index)

    # 5. ìµœì¢… ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    final_reranked_docs = [documents[i] for i in selected_indices]
    
    return final_reranked_docs

# app.pyì—ì„œ í˜¸ì¶œí•  ìµœì¢… í•¨ìˆ˜ëª…
rerank_documents = rerank_documents_mmr